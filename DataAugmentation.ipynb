{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynMyEYewXWeD"
      },
      "outputs": [],
      "source": [
        "# all imports\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageEnhance\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format=\"retina\"\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import math\n",
        "from IPython import display\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import TensorDataset\n",
        "import pdb\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import r2_score, explained_variance_score, mean_absolute_error\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# upload train df\n",
        "traindf = pd.read_csv(\"train.csv\")"
      ],
      "metadata": {
        "id": "zYrTh4naXcSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dictionary of # of instances for each acne type\n",
        "double_array = [[\" blackheads\", 230], [\" dark spot\", 605], [\" nodules\", 147], [\" papules\", 645], [\" pustules\", 361], [\" whiteheads\", 317]]\n",
        "classCount = {item[0]: item[1] for item in double_array}"
      ],
      "metadata": {
        "id": "VxNVlnoDXcPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# iterate through all classes\n",
        "for a_type in classCount:\n",
        "  # depending on count, over sample more or le\n",
        "  count = classCount[a_type]\n",
        "  if count < 300:\n",
        "    count_to_change = int((0.18 * count) / 3)\n",
        "  else:\n",
        "    count_to_change = int((0.05 * count) / 3)\n",
        "\n",
        "  change_im_df = traindf[traindf[a_type] == 1].sample(n=count_to_change)\n",
        "\n",
        "  count = 0\n",
        "  for idx, row in change_im_df.iterrows():\n",
        "    count += 1\n",
        "    # open original image\n",
        "    image_path = row['filename']\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "\n",
        "    # apply shear transformation\n",
        "    sheared_im = image.transform(image.size, Image.AFFINE, (1, 0.2, 0, 0.3, 1, 0), fillcolor='black')\n",
        "    # save altered image\n",
        "    sheared_filename = os.path.join(f\"new_sheared_{count}.png\")\n",
        "    sheared_im.save(sheared_filename)\n",
        "    #duplicate row (have same blackhead, whitehead etc properties) but change the filename to the altered image path\n",
        "    df_new_shear = traindf.loc[traindf['filename'] == image_path].copy()\n",
        "    df_new_shear['filename'] = sheared_filename\n",
        "    # add back into traindf\n",
        "    traindf = pd.concat([traindf, df_new_shear], ignore_index=True)\n",
        "\n",
        "\n",
        "    # apply resize (pixelate)\n",
        "    pixelated_im = image.resize((300, 226))\n",
        "    # save altered image\n",
        "    pixelated_filename = os.path.join(f\"new_pixelated_{count}.png\")\n",
        "    pixelated_im.save(pixelated_filename)\n",
        "    # duplicate row (have same blackhead, whitehead etc properties) but change the filename to the altered image path\n",
        "    df_new_pixel = traindf.loc[traindf['filename'] == image_path].copy()\n",
        "    df_new_pixel['filename'] = pixelated_filename\n",
        "    # add back into traindf\n",
        "    traindf = pd.concat([traindf, df_new_pixel], ignore_index=True)\n",
        "\n",
        "    # apply brightness reduction\n",
        "    enhancer = ImageEnhance.Brightness(image)\n",
        "    darker_im = enhancer.enhance(0.5)\n",
        "    # save altered image\n",
        "    darker_filename = os.path.join(f\"new_darker_{count}.png\")\n",
        "    darker_im.save(darker_filename)\n",
        "    # duplicate row (have same blackhead, whitehead etc properties) but change the filename to the altered image path\n",
        "    df_new_darker = traindf.loc[traindf['filename'] == image_path].copy()\n",
        "    df_new_darker['filename'] = darker_filename\n",
        "    # add back into traindf\n",
        "    traindf = pd.concat([traindf, df_new_darker], ignore_index=True)"
      ],
      "metadata": {
        "id": "d9M5u_XlXcKA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}